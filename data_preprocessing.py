# -*- coding: utf-8 -*-
"""Data preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tffo6jXlApGC-djPFm0GOH7sCmbaK2n1

**importing libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.impute import SimpleImputer 
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.model_selection import train_test_split



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline 
plt.style.use("fivethirtyeight")

"""**Import data**"""

data = pd.read_csv("/content/Data.csv")

y= data.iloc[:,3] #type DataFrame
x= data.iloc[:,:3]
#or 
x= data.iloc[:,:3].values #type numpy
y= data.iloc[:,3].values

"""**Encoding Categorical Data**"""

x_encoded= pd.get_dummies(x,columns=["Country"])
x= x_encoded[:,1:].to_numpy()

labelencoder_y=LabelEncoder()
y=labelencoder_y.fit_transform(y)

"""**taking care of missing data**"""

#simple way to do it manually 
'''data["Salary"].fillna(value=data["Salary"].mean())
   data["Age"].fillna(value=data["Age"].mode()) '''

# or to do it at once
imputer = SimpleImputer(missing_values=np.nan,strategy="mean")
imputer.fit(x[:,:2])
x[:,:2]=imputer.transform(x[:,:2])

"""**Splitting The dataset**"""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2,random_state=0)

"""**Feature scaling**"""

sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)

*** for balancing data ***
 we use SMOTEtomek lib 
